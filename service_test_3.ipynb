{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.739 Gb\n",
      "all cohesion probabilities was computed. # words = 126055\n",
      "all branching entropies was computed # words = 226020\n",
      "all accessor variety was computed # words = 226020\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import category\n",
    "from NewsAnalyzer.Analyzer import analysis\n",
    "from NewsAnalyzer.PreProcesser import preprocesser\n",
    "\n",
    "pp = preprocesser()\n",
    "an = analysis()\n",
    "\n",
    "def save_file(df,cg):\n",
    "    df.to_csv(\"result_data/\"+date+\" \"+cg+\" \"+\"result.csv\")\n",
    "\n",
    "def category_get_result(df,cg,corpus):\n",
    "    df_p = pp.select_category(df,cg)\n",
    "    all_n = pp.prep(corpus,df=df_p,title=True,tokenizing=False)\n",
    "    all_keywords = an.get_result(all_n)\n",
    "    save_file(all_keywords,cg)\n",
    "\n",
    "date = \"2022-04-18\"\n",
    "file_path = \"data/\"+date+\" news data.csv\"\n",
    "\n",
    "df = pp.load_data(file_path)\n",
    "corpus = pp.make_corpus(file_path)\n",
    "\n",
    "df_p = pp.select_category(df,\"경제\")\n",
    "all_n = pp.prep(corpus,df=df_p,title=True,tokenizing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 818\n",
      "done = 10 Early stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "all_keywords = an.get_result(all_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>키워드</th>\n",
       "      <th>중요도</th>\n",
       "      <th>연관단어</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성</td>\n",
       "      <td>4.330682</td>\n",
       "      <td>[sdi, 과징금, 업체, 기술자료, 하도급, 공정위, 중국, 유출, 신저가, 하청]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>해제</td>\n",
       "      <td>2.721766</td>\n",
       "      <td>[거리두기, 전면, 금리, 코로나, 오늘부터, 화장품, 완화, 인상, 확진자, 시장]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LG</td>\n",
       "      <td>2.592932</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>시장</td>\n",
       "      <td>2.347101</td>\n",
       "      <td>[진출, nft, 글로벌, 현대차, 업계, 최초, 부동산, 중고차, 발표, 성장]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>금리</td>\n",
       "      <td>2.255471</td>\n",
       "      <td>[인상, 이자, 대출, 은행, 오르면, 시장, 한국, 10, 이창용, 글로벌]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>아파트</td>\n",
       "      <td>2.241196</td>\n",
       "      <td>[삼성, 서울, 구축, 재건축, 강남, 절반, 서초, 거래, 규제, 대선]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>거리두기</td>\n",
       "      <td>2.200972</td>\n",
       "      <td>[해제, 전면, 금리, 코로나, 오늘부터, 화장품, 완화, 인상, 확진자, 시장]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>재건축</td>\n",
       "      <td>1.812765</td>\n",
       "      <td>[아파트, 삼성, 서울, 구축, 강남, 절반, 서초, 거래, 규제, 대선]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>코로나</td>\n",
       "      <td>1.571091</td>\n",
       "      <td>[실적, 쌍용차, 쌍방울, 인수, 분양, 아파트, 일부, 인상, 흑자, 최대]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>서울</td>\n",
       "      <td>1.525189</td>\n",
       "      <td>[아파트, 삼성, 구축, 재건축, 강남, 절반, 서초, 거래, 규제, 대선]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>구축</td>\n",
       "      <td>1.509068</td>\n",
       "      <td>[아파트, 삼성, 서울, 재건축, 강남, 절반, 서초, 거래, 규제, 대선]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>글로벌</td>\n",
       "      <td>1.499086</td>\n",
       "      <td>[시장, 진출, nft, 현대차, 업계, 최초, 부동산, 중고차, 발표, 성장]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>기술</td>\n",
       "      <td>1.476740</td>\n",
       "      <td>[도시, 속도, 기대감, 기업, 새벽배송, 3배, 추경호, 증시, 집값, 물가]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>기대</td>\n",
       "      <td>1.433957</td>\n",
       "      <td>[정부, 공개, 힐스테이트, 종합, ipo, 다시, 한다, 위기, 주목, 구축]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>공급</td>\n",
       "      <td>1.364509</td>\n",
       "      <td>[뱅크, 카카오, 돌파, 대출, 전월세보증금, 13조, 카뱅, 13조원, 10, 청...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>투자</td>\n",
       "      <td>1.352316</td>\n",
       "      <td>[쌍용차, 20, 쌍방울, 금융, 경제, 4년, 인수, 수익률, 흑자, 증시]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>분양</td>\n",
       "      <td>1.331727</td>\n",
       "      <td>[코로나, 성장, 봉쇄, 경제, 물가, 청약, 세운, 상승, 19, 도시]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20</td>\n",
       "      <td>1.331260</td>\n",
       "      <td>[실적, 세운, 청약, 1분기, 그래비티, 푸르지오, 19, 깜짝, 상승, 임대주택]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>상승</td>\n",
       "      <td>1.303806</td>\n",
       "      <td>[카드, 투자, 포바이포, 공모가, 확정, 물가, 1만7000원, 상단, 모니모, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>실적</td>\n",
       "      <td>1.278672</td>\n",
       "      <td>[세운, 청약, 20, 1분기, 그래비티, 푸르지오, 19, 깜짝, 상승, 임대주택]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     키워드       중요도                                               연관단어\n",
       "0     삼성  4.330682    [sdi, 과징금, 업체, 기술자료, 하도급, 공정위, 중국, 유출, 신저가, 하청]\n",
       "1     해제  2.721766    [거리두기, 전면, 금리, 코로나, 오늘부터, 화장품, 완화, 인상, 확진자, 시장]\n",
       "2     LG  2.592932                                               None\n",
       "3     시장  2.347101      [진출, nft, 글로벌, 현대차, 업계, 최초, 부동산, 중고차, 발표, 성장]\n",
       "4     금리  2.255471        [인상, 이자, 대출, 은행, 오르면, 시장, 한국, 10, 이창용, 글로벌]\n",
       "5    아파트  2.241196          [삼성, 서울, 구축, 재건축, 강남, 절반, 서초, 거래, 규제, 대선]\n",
       "6   거리두기  2.200972      [해제, 전면, 금리, 코로나, 오늘부터, 화장품, 완화, 인상, 확진자, 시장]\n",
       "7    재건축  1.812765          [아파트, 삼성, 서울, 구축, 강남, 절반, 서초, 거래, 규제, 대선]\n",
       "8    코로나  1.571091        [실적, 쌍용차, 쌍방울, 인수, 분양, 아파트, 일부, 인상, 흑자, 최대]\n",
       "9     서울  1.525189         [아파트, 삼성, 구축, 재건축, 강남, 절반, 서초, 거래, 규제, 대선]\n",
       "10    구축  1.509068         [아파트, 삼성, 서울, 재건축, 강남, 절반, 서초, 거래, 규제, 대선]\n",
       "11   글로벌  1.499086       [시장, 진출, nft, 현대차, 업계, 최초, 부동산, 중고차, 발표, 성장]\n",
       "12    기술  1.476740       [도시, 속도, 기대감, 기업, 새벽배송, 3배, 추경호, 증시, 집값, 물가]\n",
       "13    기대  1.433957       [정부, 공개, 힐스테이트, 종합, ipo, 다시, 한다, 위기, 주목, 구축]\n",
       "14    공급  1.364509  [뱅크, 카카오, 돌파, 대출, 전월세보증금, 13조, 카뱅, 13조원, 10, 청...\n",
       "15    투자  1.352316        [쌍용차, 20, 쌍방울, 금융, 경제, 4년, 인수, 수익률, 흑자, 증시]\n",
       "16    분양  1.331727          [코로나, 성장, 봉쇄, 경제, 물가, 청약, 세운, 상승, 19, 도시]\n",
       "17    20  1.331260    [실적, 세운, 청약, 1분기, 그래비티, 푸르지오, 19, 깜짝, 상승, 임대주택]\n",
       "18    상승  1.303806  [카드, 투자, 포바이포, 공모가, 확정, 물가, 1만7000원, 상단, 모니모, ...\n",
       "19    실적  1.278672    [세운, 청약, 20, 1분기, 그래비티, 푸르지오, 19, 깜짝, 상승, 임대주택]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k():\n",
    "    try:\n",
    "        a = [1,2,3,4,5]\n",
    "        print(a[8])\n",
    "    except:\n",
    "        print(\"10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 3418\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 922\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 280\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 415\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 918\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 296\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 543\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 269\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 527\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 770\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 267\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 611\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 400\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 831\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 342\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 337\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 161\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 173\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 356\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 257\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 442\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 419\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 87\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 109\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 373\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 219\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 407\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 1320\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 89\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 651\n",
      "done = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sh\\study\\비정형데이터분석프로젝트\\NewsAnalyzer\\show_relevant_article.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[j] = top_word_30[i]\n",
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 9885\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 886\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 134\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 187\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 78\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 517\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 790\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 636\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 139\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 265\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 1057\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 273\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 354\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 617\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 172\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 468\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 567\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 54\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 290\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 250\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 450\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 232\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 450\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 197\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 326\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 461\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 291\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 438\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 308\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 456\n",
      "done = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sh\\study\\비정형데이터분석프로젝트\\NewsAnalyzer\\show_relevant_article.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[j] = top_word_30[i]\n",
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 12117\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 749\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 648\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 816\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 307\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 833\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 817\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 255\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 1030\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 419\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 200\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 322\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 256\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 227\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 778\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 300\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 386\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 318\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 1186\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 552\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 326\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 571\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 1029\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 810\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 315\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 470\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 252\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 243\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 795\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 672\n",
      "done = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sh\\study\\비정형데이터분석프로젝트\\NewsAnalyzer\\show_relevant_article.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[j] = top_word_30[i]\n",
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 1701\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 187\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 931\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 168\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 144\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 38\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 237\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 73\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 99\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 126\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 145\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 35\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 233\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 172\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 28\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 78\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 62\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 238\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 112\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 74\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 141\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 141\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 57\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 70\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 111\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 61\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 96\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 143\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 37\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 171\n",
      "done = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sh\\study\\비정형데이터분석프로젝트\\NewsAnalyzer\\show_relevant_article.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[j] = top_word_30[i]\n",
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 1821\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 232\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 237\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 157\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 246\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 116\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 151\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 232\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 149\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 106\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 210\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 99\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 207\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 157\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 114\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 187\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 109\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 65\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 217\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 128\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 142\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 202\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 91\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 153\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 77\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 43\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 54\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 161\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 83\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 47\n",
      "done = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sh\\study\\비정형데이터분석프로젝트\\NewsAnalyzer\\show_relevant_article.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[j] = top_word_30[i]\n",
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 1352\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 328\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 318\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 95\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 91\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 48\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 254\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 148\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 51\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 127\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 208\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 328\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 176\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 195\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 136\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 77\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 457\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 110\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 182\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 99\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 71\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 208\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 151\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 112\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 113\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 271\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 80\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 141\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 115\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 59\n",
      "done = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\sh\\study\\비정형데이터분석프로젝트\\NewsAnalyzer\\show_relevant_article.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[j] = top_word_30[i]\n",
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 1.291 Gb\n",
      "all cohesion probabilities was computed. # words = 126055\n",
      "all branching entropies was computed # words = 226020\n",
      "all accessor variety was computed # words = 226020\n",
      "scan vocabs ... \n",
      "num vocabs = 2434\n",
      "done = 9 Early stopped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tmdgh\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scan vocabs ... \n",
      "num vocabs = 624\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 818\n",
      "done = 10 Early stopped.\n",
      "scan vocabs ... \n",
      "num vocabs = 1139\n",
      "done = 10 Early stopped.\n",
      "scan vocabs ... \n",
      "num vocabs = 119\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 129\n",
      "done = 10\n",
      "scan vocabs ... \n",
      "num vocabs = 202\n",
      "done = 10\n"
     ]
    }
   ],
   "source": [
    "from unicodedata import category\n",
    "from NewsAnalyzer.Analyzer import analysis\n",
    "from NewsAnalyzer.PreProcesser import preprocesser\n",
    "from NewsAnalyzer.show_relevant_article import show_relevant_article\n",
    "\n",
    "pp = preprocesser()\n",
    "an = analysis()\n",
    "\n",
    "def save_file(df,cg):\n",
    "    df.to_csv(\"result_data/\"+date+\" \"+cg+\" \"+\"result.csv\")\n",
    "\n",
    "def category_get_result(df,cg,corpus):\n",
    "    if cg != \"all\":\n",
    "        df_p = pp.select_category(df,cg)\n",
    "    else:\n",
    "        df_p = df\n",
    "    all_n = pp.prep(corpus,df=df_p,title=True,tokenizing=False)\n",
    "    all_keywords = an.get_result(all_n)\n",
    "    return all_keywords\n",
    "\n",
    "date = \"2022-04-18\"\n",
    "file_path = \"data/\"+date+\" news data.csv\"\n",
    "\n",
    "df = pp.load_data(file_path)\n",
    "\n",
    "df_p_2 = show_relevant_article(\"정치\",df)\n",
    "df_e_2 = show_relevant_article(\"경제\",df)\n",
    "df_s_2 = show_relevant_article(\"사회\",df)\n",
    "df_l_2 = show_relevant_article(\"생활\",df)\n",
    "df_i_2 = show_relevant_article(\"IT\",df)\n",
    "df_w_2 = show_relevant_article(\"세계\",df)\n",
    "\n",
    "corpus = pp.make_corpus(file_path)\n",
    "\n",
    "# 전체 데이터\n",
    "category_get_result(df,\"all\",corpus)\n",
    "\n",
    "# 카테고리 : 정치, 경제, 사회, 생활, IT, 세계\n",
    "df_p_1 = category_get_result(df,\"정치\",corpus)\n",
    "df_e_1 = category_get_result(df,\"경제\",corpus)\n",
    "df_s_1 = category_get_result(df,\"사회\",corpus)\n",
    "df_l_1 = category_get_result(df,\"생활\",corpus)\n",
    "df_i_1 = category_get_result(df,\"IT\",corpus)\n",
    "df_w_1 = category_get_result(df,\"세계\",corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정호영'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p_1[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_link(df1, df2):\n",
    "    # df1 : 키워드, 연관단어\n",
    "    # df2 : 기사링크\n",
    "    for i in range(len(df1)):\n",
    "        articles = []\n",
    "        for j in range(len(df2)):\n",
    "            if df1[0][0] == df2.labels.iloc[j]:\n",
    "                articles.append([df2.기사제목.iloc[j],df2.기사링크.iloc[j],df2.본문.iloc[j]])\n",
    "        df1[i].append(articles)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def make_df(data):\n",
    "    df = pd.DataFrame(data,columns=[\"키워드\",\"중요도\",\"연관단어\",\"기사링크\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p_3 = add_link(df1 = df_p_1, df2=df_p_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_summ(df):\n",
    "    for i in range(len(df)):\n",
    "        data = df[i][4][0][2]\n",
    "        text = an.summarizer(data)\n",
    "        df[i].append(text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n장제원 대통령 당선인 비서실장이 지난 17일 서울 종로구 통의동 대통령직인수위원회 앞에서 취재진의 질문에 답하고 있다./인수위사진기자단[서울경제] 장제원 대통령 당선인 비서실장이 정호영 보건복지부 장관 후보자를 둘러싼 \\'아빠 찬스\\' 논란이 조국 전 법무부 장관 사태를 연상시킨다는 지적에 \"뭐가 같냐\"고 말했다.장 실장은 18일 오전 출근길에 기자들과 만나 \"(정 후보자가) 조작했습니까? 위조했습니까? 뭐가 똑같은지 얘기해보라\"며 이같이 밝혔다. 그는 \"이제 앞으로 프레임 하지 말고 검증하시라\"며 \"입시, 병역 문제에 있어서 팩트로 밝혀진 게 있으면 얘기해보라\"고 덧붙였다. 더불어민주당 등에서 정 후보자의 사퇴를 압박하고 있는 가운데 \\'엄호\\'에 나선 것 아니냐는 해석이 나온다.이어 장 실장은 \"(정 후보자 자녀가) 아버지 대학에 갔다. 아버지는 대학교수고, 병원장인데 아이가 그 대학에 가고 싶어 실력으로 갔다는 것\"이라며 \"아버지와 자식이 그렇게 얘기하는데, 조국 문제와 이게 비슷한 것 있으면 얘기해보라\"고 재차 강조했다.그러면서 장 실장은 \"자신이 복지부 장관이 되더라도 문제가 생기면 그만두고 법적인 책임까지 지겠다는데 어떻게 얘기해야 하느냐\"며 \"당선인이 \\'여론이 안 좋습니다. 당신 그만두세요\"라고 얘기해야 하느냐\"고 반문했다.\\n\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p_3[0][6][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_p_3[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['정호영',\n",
       " 8.121961865907743,\n",
       " ['국민의힘', '합당', '조국', '선언', '청문회', '국민의', '달라', '당선인', '의혹', '판단'],\n",
       " '장제원 대통령 당선인 비서실장이 18일 오전 출근길에 기자들과 만나 정호영 보건복지부 장관 후보자를 둘러싼 \\'아빠 찬스\\' 논란이 조국 전 법무부 장관 사태를 연상시킨다는 지적에 \"뭐가 같냐\"고 말했다.']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_p_3[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83d3e1d533d06a5ed13bdd408cfdbe5752516a627e355ce33664633b6ff4534e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
